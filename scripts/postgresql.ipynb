{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb16fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: d:\\docs\\MADS\\699\\scripts\n",
      "Found 5 parquet files:\n",
      "  ../data/raw\\train-00000-of-00005.parquet\n",
      "  ../data/raw\\train-00001-of-00005.parquet\n",
      "  ../data/raw\\train-00002-of-00005.parquet\n",
      "  ../data/raw\\train-00003-of-00005.parquet\n",
      "  ../data/raw\\train-00004-of-00005.parquet\n",
      "\n",
      "Processing file 1/5: train-00000-of-00005.parquet\n",
      "  Loaded 3990 rows\n",
      "  Columns: ['image', 'label']\n",
      "  Image column type: <class 'dict'>\n",
      "  Extracting image bytes from dictionary...\n",
      "  Successfully loaded 3990 rows to database\n",
      "\n",
      "Processing file 2/5: train-00001-of-00005.parquet\n",
      "  Loaded 3990 rows\n",
      "  Extracting image bytes from dictionary...\n",
      "  Successfully loaded 3990 rows to database\n",
      "\n",
      "Processing file 3/5: train-00002-of-00005.parquet\n",
      "  Loaded 3989 rows\n",
      "  Extracting image bytes from dictionary...\n"
     ]
    }
   ],
   "source": [
    "# This file loads all raw parquet data files into the raw_documents table\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "# Define the data directory path\n",
    "data_dir = '../data/raw'\n",
    "\n",
    "# Check if directory exists\n",
    "if not os.path.exists(data_dir):\n",
    "    print(f\"Data directory not found: {data_dir}\")\n",
    "    print(\"Available directories:\")\n",
    "    for root, dirs, files in os.walk('/workspace'):\n",
    "        if 'data' in dirs or any('parquet' in f for f in files):\n",
    "            print(f\"  {root}\")\n",
    "    exit(1)\n",
    "\n",
    "# Find all parquet files\n",
    "parquet_files = glob.glob(os.path.join(data_dir, \"*.parquet\"))\n",
    "print(f\"Found {len(parquet_files)} parquet files:\")\n",
    "for file in parquet_files:\n",
    "    print(f\"  {file}\")\n",
    "\n",
    "if not parquet_files:\n",
    "    print(\"No parquet files found!\")\n",
    "    exit(1)\n",
    "\n",
    "# Create database connection\n",
    "engine = create_engine('postgresql://postgres:123@localhost:5432/postgres')\n",
    "\n",
    "# Load each parquet file and append to database\n",
    "total_rows = 0\n",
    "for i, file_path in enumerate(parquet_files):\n",
    "    try:\n",
    "        print(f\"\\nProcessing file {i+1}/{len(parquet_files)}: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # Read parquet file\n",
    "        df = pd.read_parquet(file_path)\n",
    "        print(f\"  Loaded {len(df)} rows\")\n",
    "\n",
    "        # Show columns for first file\n",
    "        if i == 0:\n",
    "            print(f\"  Columns: {df.columns.tolist()}\")\n",
    "            print(f\"  Image column type: {type(df['image'].iloc[0])}\")\n",
    "\n",
    "        # Extract bytes from the image dictionary\n",
    "        print(f\"  Extracting image bytes from dictionary...\")\n",
    "        df['image'] = df['image'].apply(lambda x: x['bytes'] if isinstance(x, dict) else x)\n",
    "\n",
    "        # Load to documents table (not raw_documents, we need the table with BYTEA column)\n",
    "        df.to_sql('documents', engine, if_exists='append', index=False, method='multi')\n",
    "        \n",
    "        total_rows += len(df)\n",
    "        print(f\"  Successfully loaded {len(df)} rows to database\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {file_path}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"Total files processed: {len(parquet_files)}\")\n",
    "print(f\"Total rows loaded: {total_rows}\")\n",
    "print(\"Data loading completed!\")\n",
    "\n",
    "# Verify the data in database\n",
    "try:\n",
    "    result = pd.read_sql(\"SELECT COUNT(*) as total_rows FROM documents\", engine)\n",
    "    print(f\"Total rows in database: {result['total_rows'].iloc[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error verifying data: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
